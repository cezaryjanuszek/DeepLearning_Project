{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import *\n",
    "\n",
    "\n",
    "\n",
    "from torch import empty, cat, arange\n",
    "from torch.nn.functional import fold, unfold\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.7625,  0.1708, -0.1781,  0.9177],\n",
       "           [ 0.1090,  0.9607,  0.5122, -0.6102],\n",
       "           [-0.8960,  0.6751, -1.7255, -1.3522],\n",
       "           [ 0.4167, -0.9028, -1.2607, -0.7607]],\n",
       " \n",
       "          [[-0.2336,  0.3692, -1.5689, -1.3419],\n",
       "           [ 0.3439, -0.5653,  0.1135, -1.2895],\n",
       "           [-0.2301,  1.0384, -0.0396,  1.1815],\n",
       "           [ 0.3712, -1.6379,  0.5888,  0.9896]],\n",
       " \n",
       "          [[-0.3111, -0.4093,  0.9849,  0.5334],\n",
       "           [ 0.2598,  0.4593,  0.0198, -0.8385],\n",
       "           [-0.4612, -0.2769,  0.6749, -2.8046],\n",
       "           [-1.1521,  0.2051, -0.1032,  0.9607]]]]),\n",
       " tensor([[[[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 3, 4, 4))\n",
    "\n",
    "# x = torch.tensor(\n",
    "    # [[0, 1., 0],     \n",
    "    # [2, 0, 0],\n",
    "    # [0, 0, 1]])\n",
    "\n",
    "# y = torch.ones(x.shape)\n",
    "y = torch.ones((1, 3, 4, 4))\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1194, -0.1194, -0.1194],\n",
       "          [-0.1194, -0.1194, -0.1194],\n",
       "          [-0.1194, -0.1194, -0.1194]],\n",
       "\n",
       "         [[ 0.6854,  0.6854,  0.6854],\n",
       "          [ 0.6854,  0.6854,  0.6854],\n",
       "          [ 0.6854,  0.6854,  0.6854]],\n",
       "\n",
       "         [[ 0.1693,  0.1693,  0.1693],\n",
       "          [ 0.1693,  0.1693,  0.1693],\n",
       "          [ 0.1693,  0.1693,  0.1693]],\n",
       "\n",
       "         [[ 0.1380,  0.1380,  0.1380],\n",
       "          [ 0.1380,  0.1380,  0.1380],\n",
       "          [ 0.1380,  0.1380,  0.1380]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 4, 2)\n",
    "expected = conv(y)\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Unfold(kernel_size=2)(x)\n",
    "\n",
    "kernel_size = (2, 2)\n",
    "out_channels = 4\n",
    "\n",
    "# Output of convolution as a matrix product\n",
    "unfolded = torch.nn.functional.unfold(y, kernel_size=kernel_size)\n",
    "# unfolded\n",
    "\n",
    "wxb = conv.weight.view(out_channels, -1) @ unfolded + conv.bias.view(1, -1, 1)\n",
    "actual = wxb.view(1, out_channels, y.shape[2] - kernel_size[0] + 1, y.shape[3] - kernel_size[1]+ 1)\n",
    "torch.testing.assert_allclose(actual, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Conv2d Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing our conv2d layer\n",
    "my_conv = Conv2d(3, 4, 2)\n",
    "x2 = my_conv.forward(x)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(my_conv.forward(x), torch.nn.functional.conv2d(x, my_conv.weight, my_conv.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2.view(3, -1) @ w.view(4, -1).t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = my_conv.weight\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_unfolded = unfold(x, kernel_size=2)\n",
    "out_unfolded = my_conv.weight.view(4, -1) @ in_unfolded + my_conv.bias.view(1, -1, 1)\n",
    "ouput = out_unfolded.view(x.shape[0], self.output_channels, tensor.shape[2]-self.kernel_size[0]+1, tensor.shape[3]-self.kernel_size[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33612/19919078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\czare\\EPFL\\MA2\\DeepLearning\\DeepLearning_Project\\Proj_262813_342141_287050\\Miniproject_2\\model.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, *gradwrtoutput)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Apply backward function as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\czare\\EPFL\\MA2\\DeepLearning\\DeepLearning_Project\\Proj_262813_342141_287050\\Miniproject_2\\model.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(gradwrtoutput)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_grad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_x\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_grad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "my_conv.backward(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our TransposeConv2d layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_conv = TransposeConv2d(3, 5, 2)\n",
    "y_expected = my_t_conv.forward(x)\n",
    "y_expected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(my_t_conv.forward(x), torch.nn.functional.conv_transpose2d(x, my_t_conv.weight, my_t_conv.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.view(out_channels, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 9])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 9])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wxb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.7311, 0.5000],\n",
       "        [0.8808, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.7311]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relu = ReLU()\n",
    "f=Sigmoid()\n",
    "\n",
    "f.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.2689, 0.5000],\n",
       "        [0.1192, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.2689]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.backward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05c62fd4a2c0b8f9b34fd07d525d94a1e9beb33a056c649ea73d5b364e4320b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
