{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch import empty, cat, arange\n",
    "from torch.nn.functional import fold, unfold\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from model import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image data\n",
    "noisy_imgs_1, noisy_imgs_2 = torch.load('../../data/train_data.pkl')\n",
    "noisy_imgs, clean_imgs = torch.load('../../data/val_data.pkl')\n",
    "\n",
    "train_input, train_target = noisy_imgs_1.float()/255.0, noisy_imgs_2.float()/255.0 \n",
    "test_input, test_target = noisy_imgs.float()/255.0, clean_imgs.float()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take batch of size 10\n",
    "input_batch = train_input[:100,:,:,:]\n",
    "target_batch = train_target[:10,:,:,:]\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some tensors for simple tests\n",
    "x = torch.randn((1, 3, 4, 4))\n",
    "\n",
    "# y = torch.ones(x.shape)\n",
    "y = torch.ones((1, 3, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Conv2d Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([10, 3, 32, 32]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 16, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing our conv2d layer\n",
    "my_conv = Conv2d(3, 4, 2, stride=2)\n",
    "output = my_conv.forward(input_batch)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(my_conv.forward(input_batch), torch.nn.functional.conv2d(input_batch, my_conv.weight, my_conv.bias, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 32, 32)\n",
    "conv = Conv2d(3, 3, 3)\n",
    "torch.testing.assert_allclose(conv.forward(x), torch.nn.functional.conv2d(x, conv.weight, conv.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back = my_conv.backward(output)\n",
    "back.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Upsampling (TransposeConv2d) layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = input_batch[:1,:,:,:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 64, 64])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_conv = Upsampling(3, 5, 2, stride=2)\n",
    "upsampled = my_t_conv.forward(x)\n",
    "upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1024])\n",
      "torch.Size([5, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "torch.testing.assert_allclose(my_t_conv.forward(x), torch.nn.functional.conv_transpose2d(x, my_t_conv.weight, my_t_conv.bias, stride=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_t = my_t_conv.backward(upsampled)\n",
    "back_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 6, 6]), torch.Size([1, 3, 4, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(Conv2d(3,4,2), Upsampling(4,3,2, stride=2))\n",
    "forward_pass = model.forward(x)\n",
    "backward_pass = model.backward(forward_pass)\n",
    "forward_pass.shape, backward_pass.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3, 32, 32]), torch.Size([1000, 3, 32, 32]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_batch = train_input[:1000, :, :, :]\n",
    "train_target_batch = train_target[:1000, :, :, :]\n",
    "train_input_batch.shape, train_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration: loss=0.7427013516426086\n",
      "1 iteration: loss=0.7255274653434753\n",
      "2 iteration: loss=0.7243703007698059\n",
      "3 iteration: loss=0.7242486476898193\n",
      "4 iteration: loss=0.7241997122764587\n",
      "5 iteration: loss=0.7241531014442444\n",
      "6 iteration: loss=0.7241024971008301\n",
      "7 iteration: loss=0.7240540981292725\n",
      "8 iteration: loss=0.7240176796913147\n",
      "9 iteration: loss=0.7239911556243896\n",
      "10 iteration: loss=0.7239688634872437\n",
      "11 iteration: loss=0.7239482402801514\n",
      "12 iteration: loss=0.72392737865448\n",
      "13 iteration: loss=0.7238973379135132\n",
      "14 iteration: loss=0.7238321900367737\n",
      "15 iteration: loss=0.7237774729728699\n",
      "16 iteration: loss=0.7237519025802612\n",
      "17 iteration: loss=0.7237323522567749\n",
      "18 iteration: loss=0.7237142324447632\n",
      "19 iteration: loss=0.7236966490745544\n",
      "20 iteration: loss=0.723679780960083\n",
      "21 iteration: loss=0.7236634492874146\n",
      "22 iteration: loss=0.7236475944519043\n",
      "23 iteration: loss=0.7236322164535522\n",
      "24 iteration: loss=0.7236173748970032\n",
      "25 iteration: loss=0.7236026525497437\n",
      "26 iteration: loss=0.7235881090164185\n",
      "27 iteration: loss=0.7235716581344604\n",
      "28 iteration: loss=0.723550021648407\n",
      "29 iteration: loss=0.7235309481620789\n",
      "30 iteration: loss=0.7235151529312134\n",
      "31 iteration: loss=0.723499596118927\n",
      "32 iteration: loss=0.7234841585159302\n",
      "33 iteration: loss=0.723469078540802\n",
      "34 iteration: loss=0.7234537601470947\n",
      "35 iteration: loss=0.7234379053115845\n",
      "36 iteration: loss=0.7234211564064026\n",
      "37 iteration: loss=0.723403811454773\n",
      "38 iteration: loss=0.7233870625495911\n",
      "39 iteration: loss=0.7233716249465942\n",
      "40 iteration: loss=0.7233564853668213\n",
      "41 iteration: loss=0.723340630531311\n",
      "42 iteration: loss=0.7233245372772217\n",
      "43 iteration: loss=0.7233086228370667\n",
      "44 iteration: loss=0.7232932448387146\n",
      "45 iteration: loss=0.7232776880264282\n",
      "46 iteration: loss=0.723258912563324\n",
      "47 iteration: loss=0.7232326865196228\n",
      "48 iteration: loss=0.7232080101966858\n",
      "49 iteration: loss=0.7231912612915039\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train(train_input_batch, train_target_batch, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and psnr score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(denoised,ground_truth):\n",
    "    mse=torch.mean((denoised-ground_truth)**2)\n",
    "    return  - 10 * torch.log10(((denoised-ground_truth) ** 2).mean((1,2,3))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.6920)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(test_input)\n",
    "psnr(prediction, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model.model.param(), open('bestmodel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05c62fd4a2c0b8f9b34fd07d525d94a1e9beb33a056c649ea73d5b364e4320b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
