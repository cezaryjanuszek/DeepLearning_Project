{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch import empty, cat, arange\n",
    "from torch.nn.functional import fold, unfold\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from model import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image data\n",
    "noisy_imgs_1, noisy_imgs_2 = torch.load('../../data/train_data.pkl')\n",
    "noisy_imgs, clean_imgs = torch.load('../../data/val_data.pkl')\n",
    "\n",
    "train_input, train_target = noisy_imgs_1.float()/255.0, noisy_imgs_2.float()/255.0 \n",
    "test_input, test_target = noisy_imgs.float()/255.0, clean_imgs.float()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take batch of size 1\n",
    "input_batch = train_input[:10,:,:,:]\n",
    "target_batch = train_target[:10,:,:,:]\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some tensors for simple tests\n",
    "x = torch.randn((1, 3, 4, 4))\n",
    "\n",
    "# y = torch.ones(x.shape)\n",
    "y = torch.ones((1, 3, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Conv2d Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 32, 32]), torch.Size([10, 3, 32, 32]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 16, 16])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing our conv2d layer\n",
    "my_conv = Conv2d(3, 4, 2, stride=2)\n",
    "output = my_conv.forward(input_batch)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(my_conv.forward(input_batch), torch.nn.functional.conv2d(input_batch, my_conv.weight, my_conv.bias, stride=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Conv2d(3, 4, 2, stride=2)\n",
    "out = model(input_batch)\n",
    "target_out = model(target_batch)\n",
    "loss = nn.MSELoss()\n",
    "l = loss(out, target_out)\n",
    "l.requires_grad_()\n",
    "\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back = my_conv.backward(output)\n",
    "back.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Upsampling (TransposeConv2d) layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 64, 64])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_conv = Upsampling(3, 5, 2, stride=2)\n",
    "upsampled = my_t_conv.forward(input_batch)\n",
    "upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(my_t_conv.forward(input_batch), torch.nn.functional.conv_transpose2d(input_batch, my_t_conv.weight, my_t_conv.bias, stride=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_t = my_t_conv.backward(upsampled)\n",
    "back_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Conv2d(3,4,2), ReLU())\n",
    "forward_pass = model.forward(x)\n",
    "backward_pass = model.backward(forward_pass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 32, 32])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_batch = train_input[:1000, :, :, :]\n",
    "train_target_batch = train_target[:1000, :, :, :]\n",
    "train_input_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration: loss=0.7332425713539124\n",
      "1 iteration: loss=0.7236798405647278\n",
      "2 iteration: loss=0.7235281467437744\n",
      "3 iteration: loss=0.7233770489692688\n",
      "4 iteration: loss=0.7232725024223328\n",
      "5 iteration: loss=0.7231711745262146\n",
      "6 iteration: loss=0.7230492234230042\n",
      "7 iteration: loss=0.7229362726211548\n",
      "8 iteration: loss=0.722869336605072\n",
      "9 iteration: loss=0.7227900624275208\n",
      "10 iteration: loss=0.7227004170417786\n",
      "11 iteration: loss=0.7226137518882751\n",
      "12 iteration: loss=0.7225151062011719\n",
      "13 iteration: loss=0.7224360704421997\n",
      "14 iteration: loss=0.7223598957061768\n",
      "15 iteration: loss=0.7222872972488403\n",
      "16 iteration: loss=0.7222217917442322\n",
      "17 iteration: loss=0.7221630811691284\n",
      "18 iteration: loss=0.7221091985702515\n",
      "19 iteration: loss=0.7220585942268372\n",
      "20 iteration: loss=0.7220103740692139\n",
      "21 iteration: loss=0.7219637632369995\n",
      "22 iteration: loss=0.7219168543815613\n",
      "23 iteration: loss=0.7218676209449768\n",
      "24 iteration: loss=0.7218151688575745\n",
      "25 iteration: loss=0.7217597365379333\n",
      "26 iteration: loss=0.7217049598693848\n",
      "27 iteration: loss=0.7216497659683228\n",
      "28 iteration: loss=0.7215951085090637\n",
      "29 iteration: loss=0.72154301404953\n",
      "30 iteration: loss=0.7214938998222351\n",
      "31 iteration: loss=0.7214481830596924\n",
      "32 iteration: loss=0.7214046120643616\n",
      "33 iteration: loss=0.7213617563247681\n",
      "34 iteration: loss=0.7213197350502014\n",
      "35 iteration: loss=0.7212777137756348\n",
      "36 iteration: loss=0.7212350964546204\n",
      "37 iteration: loss=0.7211911082267761\n",
      "38 iteration: loss=0.7211430072784424\n",
      "39 iteration: loss=0.721082329750061\n",
      "40 iteration: loss=0.7209938764572144\n",
      "41 iteration: loss=0.7209078073501587\n",
      "42 iteration: loss=0.7208372354507446\n",
      "43 iteration: loss=0.7207649350166321\n",
      "44 iteration: loss=0.720687985420227\n",
      "45 iteration: loss=0.7205933332443237\n",
      "46 iteration: loss=0.7204743027687073\n",
      "47 iteration: loss=0.7203319072723389\n",
      "48 iteration: loss=0.7202261686325073\n",
      "49 iteration: loss=0.7201493382453918\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train(train_input_batch, train_target_batch, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and psnr score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(denoised,ground_truth):\n",
    "    mse=torch.mean((denoised-ground_truth)**2)\n",
    "    return  - 10 * torch.log10(((denoised-ground_truth) ** 2).mean((1,2,3))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.7144)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(test_input)\n",
    "psnr(prediction, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('bestmodel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05c62fd4a2c0b8f9b34fd07d525d94a1e9beb33a056c649ea73d5b364e4320b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
