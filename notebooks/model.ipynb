{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8ba72d1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x\n",
    "\n",
    "import torch\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7614f5",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4a470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_imgs_1, noisy_imgs_2 = torch.load('../data/train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06779e8-4b0d-489b-93d6-ad3a0fb0c582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_imgs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60067e6a-0164-4a7b-a461-55ddf46eb25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_imgs_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2cb1ac2a-cd0b-452f-a8da-4eae08635ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_imgs, clean_imgs = torch.load('../data/val_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0456ad07-4182-44a1-8579-1ba1d232f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(train_input,test_input):\n",
    "#     mu, std = train_input.mean(), train_input.std()\n",
    "#     train_input.sub_(mu).div_(std)\n",
    "#     test_input.sub_(mu).div_(std)\n",
    "#     return train_input,test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "387dc3c1-3333-45e8-aca8-1427a0f6d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input,train_target=noisy_imgs_1.float()/255.0,noisy_imgs_2.float()/255.0\n",
    "test_input,test_target=noisy_imgs.float()/255.0,clean_imgs.float()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d172ba55-ccea-4251-987d-e720a37c2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-> 0 Loss= tensor(0.0258, grad_fn=<DivBackward0>)\n",
      "Epoch-> 1 Loss= tensor(0.0161, grad_fn=<DivBackward0>)\n",
      "Epoch-> 2 Loss= tensor(0.0159, grad_fn=<DivBackward0>)\n",
      "Epoch-> 3 Loss= tensor(0.0159, grad_fn=<DivBackward0>)\n",
      "Epoch-> 4 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 5 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 6 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 7 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 8 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 9 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 10 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 11 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 12 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 13 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 14 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 15 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 16 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 17 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 18 Loss= tensor(0.0158, grad_fn=<DivBackward0>)\n",
      "Epoch-> 19 Loss= tensor(0.0157, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model= nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32)\n",
    "    )\n",
    "batch_size,nb_epochs=100,20\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "mse=nn.MSELoss()\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    print('Epoch->',e,end=' ')\n",
    "    losses=[]\n",
    "    for b in range(0,train_input.size(0),batch_size):\n",
    "        output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "        loss = mse(output, train_target.narrow(0, b, mini_batch_size))\n",
    "        losses.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Loss=',sum(losses)/(train_input.size(0)/batch_size),end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13302fef-dd47-403e-8413-1b58f8d15c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(denoised,ground_truth):\n",
    "    mse=torch.mean((denoised-ground_truth)**2)\n",
    "    return  - 10 * torch.log10(((denoised-ground_truth) ** 2).mean((1,2,3))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ad7e47b-439a-4794-97bf-dfd5ba16eda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.4655, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = []\n",
    "for b in tqdm(range(0, test_input.size(0), batch_size)):\n",
    "    output = model(test_input.narrow(0, b, batch_size))\n",
    "    model_outputs.append(output)\n",
    "model_outputs = torch.cat(model_outputs, dim=0)\n",
    "\n",
    "output_psnr = psnr(model_outputs, test_target)\n",
    "output_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For mini - project 1\n",
    "class Model ():\n",
    "    def __init__(self) -> None :\n",
    "        ## instantiate model + optimizer + loss function + any other stuff you need\n",
    "\n",
    "        pass\n",
    "\n",
    "    def load_pretrained_model(self) -> None :\n",
    "        ## This loads the parameters saved in bestmodel .pth into the model\n",
    "        pass\n",
    "\n",
    "    def train(self, train_input, train_target, num_epochs) -> None :\n",
    "        #: train˙input : tensor of size (N, C, H, W) containing a noisy version of the images\n",
    "\n",
    "        #: train˙target : tensor of size (N, C, H, W) containing another noisy version of the same images , which only differs from the input by their noise .\n",
    "        pass\n",
    "\n",
    "    def predict(self, test_input ) -> torch.Tensor:\n",
    "        #:test_input : tensor of size (N1 , C, H, W) that has to be denoised by the trained or the loaded network .\n",
    "        #: returns a tensor of the size (N1 , C, H, W)\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f479164b9bbf2e5d1a2ccdac69e157cad417e6bd162fe987eb3e40368ed824ca"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
